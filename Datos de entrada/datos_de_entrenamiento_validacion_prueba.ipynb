{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos de Entrenamiento, Validación y Prueba\n",
    "\n",
    "- Para este proposito, normalmente se separan los datos en tres(3).\n",
    "\n",
    "> 1. Datos de entrenamiento.\n",
    "    >> Crear el modelo de aprendizaje de máquina.\n",
    ">\n",
    "> 2. Validación.\n",
    ">\n",
    "> 3. Prueba\n",
    ">\n",
    "- Vamos a ver de que va esto:\n",
    "> 1. Imaginemos que tenemos cierto conjunto de instancias, cien(100) por ejemplo. Y que vamos a entrenar un modelo de aprendizaje de máquina **\"redes neuronales\"**. Si entrenamos esa red neuronal con esas 100 instancias y probamos esa red neuronal con algunas de esas instancias, lo más seguro es que los resultados que tengamos con este modelo sean los mejores.\n",
    "    >> **¿Porque?** - Si vamos a una analogía en la que vamos a hacer un exámen de entrevista y de este conocemos todas las respuestas a su solución, lo más seguro es que nos vaya muuuuuuuuy bien en dicho exámen.\n",
    ">\n",
    "    >> Entonces es como si la red neuronal hubiera memorizado todas las preguntas con sus respectivas respuestas pero, si por algún motivo, le hacen una pregunta que no conocia o no fue usada dentro de los datos de entrenamiento, lo más probable es que la red neuronal no sea capaz de responder a la pregunta.\n",
    ">\n",
    "    >> De acá deriva la idea de tener separados los datos de pruebas.\n",
    ">\n",
    "- Ahora vamos a ver entonces incluyendo un conjunto de datos más, que sucede.\n",
    "> 2. Tenemos un conjunto de datos del 100%. **Los dividimos en 2 partes donde el 80% de los datos son los datos de entrenamiento y el 20% restante son los datos de prueba.** Recordemos que estos datos deben ser excluyentes entre sí.\n",
    "    >> Ahora en este caso, la red neuronal estaría estudiando del conjunto de datos de entrenamiento y probando del conjunto de datos de prueba.\n",
    ">\n",
    "    >> Esto da una representación más exacta de que tan bueno puede llegar a ser nuestro modelo, al generalizar ante nuevas instancias.\n",
    ">\n",
    "    >> Claro está que en este caso, ya al modelo quizá no le vaya tan bién en comparación con la idea anterior, ya que el modelo se está probando con instancias que no conoce.\n",
    ">\n",
    "- Ahora vamos a incluir otro conjunto de datos.\n",
    "> 3. Ahora digamos que tenemos el conjunto de datos dividido en tres. **Donde tenemos el 60% de los datos son de entrenamientio, un 20% para las pruebas y el otro 20% para la validación.**\n",
    "    >> Este es usado cuándo queremos hacer una validación mas robusta de nuestro modelo.\n",
    ">\n",
    "    >> Recordemos que una red neuronal tiene muchos hiperparámetros. Que sería como el número de capas de neuronas que conforman una red neuronal y dentro de cada una de esas capas tenemos un número determinado de neuronas.\n",
    ">\n",
    "    >> Con el conjunto de validación, ajustamos todos los hiperparámetros de nuestro modelo y presentamos un nuevo conjunto de pruebas cuando se hayan definido los hiperparámetros del modelo.\n",
    ">\n",
    "    >> Por lo que podemos ver que nuestro modelo ya no le va tan bién al resolver las preguntas. Pero, en este caso, vemos que podemos tener valores de métricas que son más cercanas a la realidad y reflejan la capacidad de generalización de nuestro modelo.\n",
    ">\n",
    "- Ahora, vamos a ver con la creación de un modelo en la vida real, que porcentaje realmente debemos usar en cada uno de ellos.\n",
    "> No es de conocimiento muy exacto y depende mucho del contexto pero, podemos tener una guia que nos de una idea aproximada de los porcentajes que podemos usar.\n",
    "    >> Entrenamiento    Validación     Prueba\n",
    "            60%             20%          20%\n",
    "            80%             10%          10%\n",
    "            75%             15%          10%\n",
    "            75%             0%           25%\n",
    "            80%             0%           20%\n",
    "            70%             0%           30%\n",
    "\n",
    ">\n",
    ">\n",
    "# Ahora sí, vamos a ver esto en código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a usar los datos con la siguiente separación\n",
    "#### 60% Entrenamiento, 20% Validación y 20% Prueba\n",
    "\n",
    "- Hacemos la importación de la librería a usar y nos traemos el archivo de datos\n",
    "- Veremos que usamos una libreria llamada **train_test_split**, que solo usa entrenamiento y prueba. Como podemos recordar, si los datos no tienen hiperparametros que ajustar, no es necesario usar la validación por lo que no hay un método específico para separarlos en los 3 conjuntos de datos. Sin embargo, para este ejemplo vamos a usar los 3 métodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edad</th>\n",
       "      <th>genero</th>\n",
       "      <th>presion</th>\n",
       "      <th>colesterol</th>\n",
       "      <th>diabetico</th>\n",
       "      <th>cardiaco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    edad  genero  presion  colesterol  diabetico  cardiaco\n",
       "0     53       0      128         216          0         1\n",
       "1     53       0      138         234          0         1\n",
       "2     51       0      130         256          0         1\n",
       "3     66       1      120         302          0         1\n",
       "4     62       1      130         231          0         1\n",
       "..   ...     ...      ...         ...        ...       ...\n",
       "95    57       1      128         229          0         0\n",
       "96    61       1      120         260          0         0\n",
       "97    39       1      118         219          0         0\n",
       "98    61       0      145         307          0         0\n",
       "99    56       1      125         249          1         0\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pacientes = pd.read_csv(\"../Datos de entrada/problemas_del_corazon.csv\")\n",
    "pacientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entonces, tenemos un conjunto de datos con 100 registros(instancias) en 6 columnas.\n",
    "- Vamos a asumir que las **primeras 5 columnas** son las columnas con las características con las que vamos a entrenar un modelo.\n",
    "- Vamos a asumir que la **última columna** será la clase objetivo. Vamos a asumir que es una clasificación.\n",
    "\n",
    "#### Ahora, vamos a hacer la separación de los datos\n",
    "> Veremos que esto nos regresará 4 conjuntos de datos.\n",
    "    >> Nos entrega los datos de entrenamiento y los datos de prueba\n",
    "    >> Nos entrega la clase de entrenamiento y la clase de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72    0\n",
       "73    0\n",
       "16    1\n",
       "59    0\n",
       "66    0\n",
       "8     1\n",
       "69    0\n",
       "43    1\n",
       "7     1\n",
       "24    1\n",
       "19    1\n",
       "45    1\n",
       "61    0\n",
       "36    1\n",
       "25    1\n",
       "27    1\n",
       "78    0\n",
       "84    0\n",
       "89    0\n",
       "0     1\n",
       "Name: cardiaco, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resto, prueba, resto_clase, prueba_clase = train_test_split(\n",
    "    pacientes[[\"edad\", \"genero\", \"presion\", \"colesterol\", \"diabetico\"]],\n",
    "    pacientes[\"cardiaco\"], test_size = 0.20)\n",
    "\n",
    "#resto\n",
    "#prueba\n",
    "#resto_clase\n",
    "prueba_clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Si vemos el resultado de la ejecución para resto por ejemplo, tenemos las 5 columnas destinadas para ello y a demás vemos que, los indices de los registros estan de manera aleatoria. Y a demás tenemos 80 registros.\n",
    "- Si vemos el resultado de la ejecucion de prueba, veremos que tenemos efectivamente 20 registros para las mismas 5 columnas y que a demás su id es aleatorio.\n",
    "- En resto_clase, vemos una serie de pandas donde tenemos una longitud de 80 y que a demás tiene el nombre de nuestra variable objetivo.\n",
    "- Ya logramos hacer la separación de los datos de prueba, lo que nos falta es hacer la separación de los datos de validación y entrenamiento ya que aun están todos ahí mismo en resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrena, valida, entrena_clase, valida_clase = train_test_split(\n",
    "    resto[[\"edad\", \"genero\", \"presion\", \"colesterol\", \"diabetico\"]],\n",
    "    resto_clase, test_size = 0.25)\n",
    "\n",
    "# Porque ponemos 0.25? -> Bueno, acá en los datos tenemos 80 registros y el 25% de 80 es 20. Con esto, garantizamos que se pongan 20 registros en valida y 60 registros en entrena.\n",
    "\n",
    "#entrena\n",
    "#entrena.shape[0]\n",
    "#valida\n",
    "valida.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con esto, ya tenemos la separación aleatorizada de los datos en dentrenamiento y los datos de validación y prueba."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
